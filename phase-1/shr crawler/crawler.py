import importlib.util
spec = importlib.util.spec_from_file_location("module.name","sanskrit_transcoder/transcoder.py")
transcoder = importlib.util.module_from_spec(spec)
spec.loader.exec_module(transcoder)
transcoder.transcoder_set_dir('sanskrit_transcoder/data/transcoder');
import requests
from bs4 import BeautifulSoup as bs
import pandas as pd
import numpy as np
import codecs
import time
import re
import os


def getdatafromsite(inputline) :

	problem = []
	pbwords = []

	s_d = inputline
	s_c = s_d.replace(" ","+")
	urlname = ("http://sanskrit.inria.fr/cgi-bin/SKT/sktgraph?lex=SH&st=t&us=f&cp=t&text=" +
	           s_c + "&t=SL&topic=&mode=g&corpmode=&corpdir=&sentno=")

	print(urlname)
	page = requests.get(urlname)
	soup = bs(page.text, 'html.parser')
	#     soup.prettify()
	table = soup.table
	tablebody = table.find('table',{'class' : 'center'})
	t = pd.DataFrame(columns = ['id','level','color_class','position','chunk_no','word','lemma','pre_verb','morph','colspan','wordlenth','aux_inf'])

	i = 0
	id_= 0
	if not(tablebody) :      #### wronginputs
	    print('no table body of given inputline')
	        
	for child in tablebody.children:
	    if(child.name == 'tr') :
	        if i< 1 : 
	            linechar = []
	            c=0
	            for char in child.children :
	                linechar.append(char.string)
	                c += 1
	            i+=1
	            line = "".join(linechar)
	            linechunks = line.split("\xa0")
	            continue
	        position_ = 0
	        j =0
	        for wordtable in child.children:
	#             if(j < 20 ) :
	#                 j += 1
	#                 continue
	            c= 0
	            for ch in linechar[0:position_] :
	                if(re.match('\xa0|_',ch)) : 
	                    c+=1
	            if(wordtable.contents):
	                color_ = wordtable.table.get('class')[0]
	                colspan_= wordtable.get('colspan')
	                word_ = wordtable.table.tr.td.string
	                onclickdatas_ = wordtable.table.tr.td.get('onclick')
	                for onclickdata_ in onclickdatas_.split("<br>") :
	                    morphslist_ = re.findall(r'{ (.*?) }',onclickdata_)  #.split(' | ')
	                    ldata = str(re.search(r'{.*?}\[(.*)\]',onclickdata_).group(1))
	                    ldata = str(re.sub(r'</?a.*?>|</?i>',"",ldata))

	                    lemmadata = ldata.split(" ")
	                    if len(lemmadata) >1 :
	                        auxi_ = " ".join(lemmadata[1:])
	                    else :
	                        auxi_ = ""
	                    lemmas_ = "".join(lemmadata[0])
	                    lemmalists_ = lemmas_.split("-")
	                    if(len(lemmalists_) > 1) :
	                        preverb_ = ",".join(lemmalists_[0:(len(lemmalists_)-1)])
	                        lemmalist_ = "".join(lemmalists_[-1:]).split("_")
	                    else :
	                        preverb_ = ""
	                        lemmalist_ = "".join(lemmalists_[0]).split("_")
	                    if(len(lemmalist_) > 1):
	                        auxi_ =auxi_ + " sence of lemma = " + "".join(lemmalist_[1:(len(lemmalist_))])
	                        lemma_ = "".join(lemmalist_[0])
	                    else : 
	                        lemma_ = "".join(lemmalist_[0])             
	                    morphs_ = str(morphslist_[0])               
	                    for morph_ in morphs_.split(" | ") : 
	                        t.loc[id_] = [id_,i,color_,position_,c+1,word_,lemma_,preverb_,morph_,int(colspan_),len(word_),auxi_]
	                        if(re.match(r'grey_back',color_)) :
	                            if not (word_ == 'pop') :
	                                problem.append(id_)
	                            else :
	                                id_ = id_ - 1
	                        id_ += 1    


	                position_ += int(colspan_)
	    #                 break
	            else : 
	                position_ += 1

	#         break
	        i = i+1
	# print("input line : " + inputline + "\n")
	# print("converted line : "+line + "\n")
	# print("converted line char :" + ",".join(linechar) + "\n")
	return t

def check_conflicts(line, t,sent_id):
	# returns a dataframe
	line1=line
	chunkwords = line1.split(" ")

	df = t

	s = pd.read_csv("sandhi.txt",encoding = 'utf-8' ,sep = ',')
	cf = pd.DataFrame(columns=[str(int(j)) for j in df.id.values])
	for i in df.id.values :
		i=int(i)
		cf.loc[i] = -1
	df['word_slp1'] = df['word']
	df['word_wx'] = df['word']
	for i in df.index:
		df.loc[i,'word_slp1']   =  transcoder.transcoder_processString(df.loc[i,'word'],'roman','slp1')  ##transcoder
		df.loc[i,'word_wx']   =  transcoder.transcoder_processString(df.loc[i,'word_slp1'],'slp1','wx') 

	df['sandhi_indexs'] = ""
	df['sandhi_words'] = ""
	for i in df.index : 
	    word1 = df.loc[i,'word_slp1']
	    chunkno = (df.loc[i,'chunk_no'])
	    position1 =  df.loc[i,'position']
	    level = df.loc[i,'level']
	    color1 = df.loc[i,'color_class']
	    clspan1 = int(df.loc[i,'colspan'])
	    chunkword = chunkwords[int(chunkno)-1]
	    df1 = df.loc[(df['chunk_no'] == chunkno) ]
	    for j in df1.index :
	        if i == j :
	            cf.loc[i,str(j)] = 3
	            cf.loc[j,str(i)] = 3 
	            continue
	        if (cf.loc[i,str(j)] != 1) and (cf.loc[i,str(j)] != 0) and (cf.loc[i,str(j)] != 3):
	            cf.loc[i,str(j)] = 2
	        position2 = df1.loc[j,'position']
	        color2 = df.loc[i,'color_class']
	        word2 = df1.loc[j,'word_slp1']
	        word3 = df1.loc[j,'word']
	        if(position2 == position1 + clspan1-1) and (clspan1!=1):
	            if((color1=='yellow_back') and (color2=='carmin_back'))  :    ## check color ,iic and verb
	                continue
	            if((color2=='yellow_back') and (color1=='carmin_back'))  :    ## check color
	                continue
	          
	            
	            if(len(s.loc[(s['c1']==word1[-1:] )& (s['c2']==word2[:1])])):

	                x=s.loc[(s['c1']==word1[-1:] )& (s['c2']==word2[:1])]
	                for c3 in x['c3']:
	                    mergeword = word1[:-1] + c3 + word2[1:2]
	#                             print(mergeword+"---"+chunkword)
	                    if(re.findall(mergeword,chunkword)):               ## checking  mergedword(spl1) in chunkword
	                        df.loc[i,'sandhi_indexs'] += str(j)+", "
	                        df.loc[i,'sandhi_words'] += word3+"("+word2+"), "
	                        cf.loc[i,str(j)] = 1                             ## merge pssible so change conflict
	                        cf.loc[j,str(i)] = 1   
	                        # print(word1,word2,i,j)
	                        break
	            elif(word1[-1:]=='H'):
	                if(len(s.loc[(s['c1']==word1[-2:] )& (s['c2']==word2[:1])])):

	                    x=s.loc[(s['c1']==word1[-2:] )& (s['c2']==word2[:1])]
	                    for c3 in x['c3']:
	                        mergeword = word1[:-1] + c3 + word2[1:2]
	                        if(re.findall(mergeword,chunkword)):          ## checking  mergedword(spl1) in chunkword   
	                            df.loc[i,'sandhi_indexs'] += str(j)+", "
	                            df.loc[i,'sandhi_words'] += word3+"("+word2+"), "
	                            cf.loc[i,str(j)] = 1                        ## merge pssible so change conflict
	                            cf.loc[j,str(i)] = 1 
	                            # print(word1,word2,i,j)
	                            break
	        elif(position2 > position1 + clspan1-1) :
	            cf.loc[i,str(j)] = 0
	            cf.loc[j,str(i)] = 0

	        

	## for conflict finding 0 = no conflict,1=possible merge,2=conflict ,3=itself

	for i in df.index :
	    chunkno = df.loc[i,'chunk_no']
	    position1 =  df.loc[i,'position']
	    level = df.loc[i,'level']
	    color1 = df.loc[i,'color_class']
	    clspan1 = df.loc[i,'colspan']
	    df1 = df.loc[(df['chunk_no'] != chunkno)]
	    for j in df1.index :
	        cf.loc[i,str(j)] = 0


	#         
	                        
	#         break
	#     break
	# print(name+fname+"/dataframe_withsandhi.txt")

	# df.to_csv("dataframes/sentence_dataframes/"+str(sent_id)+".csv" ,encoding = 'utf-8' , sep=',',index = False,mode = 'w' )
	# cf.to_csv("dataframes/conflict_dataframes/"+str(sent_id)+".csv" ,encoding = 'utf-8' , sep=',',index = False,mode = 'w' )
	
	df.to_csv("55/sentence_dataframes/"+str(sent_id)+".csv" ,encoding = 'utf-8' , sep=',',index = False,mode = 'w' )
	cf.to_csv("55/conflict_dataframes/"+str(sent_id)+".csv" ,encoding = 'utf-8' , sep=',',index = False,mode = 'w' )
	return cf
	pass

def sample_crawler():
	cur_file=open('all_sents.txt','r')
	line_data=cur_file.readlines()
	done_list=[1,2,3,4,6,7,8,10,11,12,13,14,16,17,18,19,20,21,22,23,24,25,27,29,30,31,32,33,34,35,37,39,40,41,42,43,44,45,46,48,49,50,51,52,54,56,57,58,61,62,63,64,66,67,68,77,78,79,82,84,85,87,89,90,93,95,96,97,98,100,101,102,103,104,105,107,114,115,117,119,120,121,124,125,126,127,128,130,131,132,133,134,135,136,137,138,139,140,144,146,148,149,151,153,156,157,159,161,162,163,164,166,168,170,171,172,173,175,176,181,182,184,186,187,189,190,191,192,193,194,195,196,199,201,202,203,204,205,206,207,209,210,211,213,214,217,218,219,220,221,222,224,228,229,230,231,232,233,236,237,238,241,242,244,246,247,248,249,250,251,252,253,261,265,269,274,275,276,278,283,285,286,287,288,289,294,295,300,301,302,303,304,305,311,315,317,318,319,320,321,323,325,328,329,331,336,345,349,353,355,356,357,358,360,361,362,363,365,366,367,368,369,371,372,373,393,397,423,434,437,441,445,446,451,458,468,470,475,476,479,480,483,484,486,490,491,492,494,498,500,502,503,504,505,506,507,508,510,512,513,514,516,517,518,520,521,524,525,527,528,529,532,537,538,539,540,543,547,548,551,553,555,556,557,561,563,564,568,569,573,576,577,578,580,583,584,587,588,593,594,597,598,600,601,603,604,605,606,607,610,611,612,614,615,621,623,625,627,628,630,632,633,636,638,639,641,644,646,650,654,655,656,657,658,659,663,664,665,672,674,675,676,680,681,682,684,686,687,688,689,692,694,696,698,699,700,701,704,707,712,713,714,717,718,719,720,721,722,723,729,731,734,737,738,742,743,746,747,748,749,750,751,752,753,756,759,761,763,764,765,766,767,768,769,770,772,773,774,777,778,779,780,784,785,787,791,792,793,795,817,818,820,821,823,825,826,827,828,829,832,833,834,836,839,842,843,844,845,846,848,849,850,851,854,857,858,862,863,864,867,868,870,874,875,876,877,879,880,882,885,886,887,888,889,909,915,916,917,918,920,922,926,927,929,930,937,938,939,940,945,946,947,950,961,964,965,967,969,970,971,973,975,977,978,981,985,987,988,989,990,991,992,999,1002,1004,1006,1009,1010,1012,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1028,1029,1030,1032,1033,1035,1038,1045,1046,1047,1049,1051,1052,1055,1057,1060,1061,1063,1065,1067,1069,1070,1071,1072,1074,1075,1077,1079,1080,1082,1083,1084,1085,1086,1087,1090,1091,1092,1095,1097,1098,1099,1100,1103,1104,1105,1106,1107,1110,1112,1113,1114,1115,1116,1119,1120,1121,1123,1124,1125,1127,1128,1130,1131,1135,1136,1137,1138,1142,1145,1146,1147,1148,1149,1150,1151,1152,1153,1155,1156,1157,1159,1160,1161,1163,1164,1167,1168,1169,1171,1176,1179,1180,1181,1182,1183,1187,1189,1194,1198,1199,1200,1201,1208,1209,1210,1211,1212,1213,1214,1215,1217,1218,1220,1222,1223,1224,1225,1226,1229,1231,1232,1239,1241,1242,1248,1254,1257,1259,1260,1261,1262,1264,1265,1266,1267,1268,1269,1270,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1284,1285,1286,1289,1290,1291,1292,1293,1294,1295,1297,1298,1299,1300,1301,1302,1303,1305,1306,1307,1311,1314,1315,1317,1318,1319,1321,1324,1325,1327,1331,1332,1333,1334,1335,1336,1337,1339,1341,1342,1343,1344,1345,1346,1349,1351,1352,1354,1356,1357,1358,1359,1360,1361,1365,1366,1370,1371,1372,1373,1375,1377,1379,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1395,1396,1397,1398,1399,1400,1401,1403,1404,1406,1407,1408,1411,1412,1413,1414,1416,1418,1424,1426,1427,1428,1429,1430,1431,1433,1434,1435,1437,1439,1440,1442,1443,1446,1450,1451,1452,1453,1454,1455,1456,1461,1462,1465,1466,1467,1469,1470,1476,1477,1478,1479,1480,1481,1482,1484,1485,1486,1488,1489,1493,1494,1495,1496,1497,1498,1499,1502,1504,1506,1508,1509,1511,1512,1513,1514,1515,1516,1517,1520,1522,1523,1525,1527,1528,1529,1532,1533,1534,1535,1536,1537,1539,1541,1542,1544,1545,1546,1548,1551,1552,1553,1555,1558,1559,1560,1561,1562,1564,1565,1566,1567,1569,1570,1571,1573,1574,1575,1578,1581,1582,1583,1584,1586,1587,1588,1589,1590,1591,1593,1596,1597,1598,1599,1600,1601,1603,1606,1608,1609,1610,1611,1612,1613,1617,1618,1621,1622,1623,1624,1626,1627,1628,1630,1631,1632,1633,1636,1637,1638,1639,1641,1643,1650,1651,1654,1655,1657,1658,1661,1662,1663,1664,1665,1666,1667,1668,1670,1671,1672,1673,1675,1676,1677,1679,1680,1685,1687,1688,1689,1691,1692,1693,1694,1695,1696,1697,1698,1699,1701,1702,1703,1705,1706,1707,1708,1709,1712,1713,1714,1715,1718,1719,1720,1721,1723,1724,1725,1726,1727,1728,1729,1732,1734,1735,1737,1738,1740,1741,1742,1743,1746,1749,1750,1751,1756,1757,1758,1759,1760,1761,1762,1764,1766,1767,1768,1769,1771,1772,1774,1775,1778,1780,1781,1782,1783,1785,1786,1788,1789,1791,1792,1793,1797,1798,1800,1801,1803,1804,1805,1806,1807,1808,1809,1810,1812,1813,1817,1819,1820,1822,1824,1825,1826,1827,1828,1829,1830,1834,1838,1839,1840,1841,1842,1844,1846,1847,1848,1849,1853,1854,1855,1856,1857,1858,1859,1860,1861,1865,1866,1867,1869,1870,1871,1872,1873,1876,1878,1881,1883,1884,1886,1887,1895,1897,1898,1899,1900,1903,1904,1907,1909,1911,1913,1917,1918,1919,1920,1922,1923,1924,1925,1927,1928,1929,1930,1931,1932,1933,1934,1935,1938,1941,1942,1943,1945,1948,1949,1953,1955,1957,1958,1959,1960,1961,1962,1965,1966,1967,1970,1971,1972,1973,1974,1975,1979,1982,1986,1988,1991,1992,1993,1994,2000,2001,2003,2005,2007,2008,2010,2011,2012,2013,2015,2017,2018,2019,2020,2021,2024,2025,2027,2028,2030,2031,2032,2036,2037,2038,2042,2044,2046,2047,2048,2050,2051,2054,2055,2056,2057,2059,2062,2063,2064,2065,2066,2067,2068,2073,2074,2075,2078,2079,2080,2082,2084,2085,2087,2090,2091,2092,2093,2095,2101,2102,2105,2110,2111,2112,2113,2114,2115,2119,2120,2123,2124,2125,2128,2129,2132,2134,2135,2137,2138,2139,2140,2141,2144,2145,2146,2147,2148,2149,2150,2157,2158,2160,2161,2162,2163,2167,2168,2169,2170,2171,2172,2174,2177,2180,2183,2185,2186,2187,2188,2189,2190,2191,2195,2196,2197,2199,2202,2203,2204,2206,2208,2209,2210,2211,2212,2214,2216,2218,2221,2224,2228,2229,2231,2232,2233,2234,2235,2237,2238,2239,2241,2246,2247,2249,2250,2251,2252,2253,2256,2257,2258,2260,2262,2263,2264,2266,2269,2270,2275,2276,2280,2286,2287,2290,2292,2293,2296,2298,2299,2301,2303,2305,2306,2307,2309,2310,2313,2315,2317,2319,2320,2324,2327,2328,2329,2330,2332,2333,2334,2336,2338,2340,2341,2342,2345,2346,2347,2348,2349,2350,2351,2352,2354,2355,2356,2358,2362,2364,2365,2366,2367,2369,2371,2372,2374,2376,2377,2378,2381,2386,2387,2388,2389,2390,2391,2392,2393,2394,2397,2398,2401,2406,2407,2408,2409,2411,2412,2413,2414,2415,2418,2419,2421,2423,2424,2426,2427,2428,2431,2432,2436,2437,2438,2441,2443,2448,2450,2451,2455,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2470,2472,2473,2475,2478,2479,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2498,2499,2500,2501,2502,2503,2505,2507,2508,2510,2511,2512,2513,2516,2517,2518,2519,2520,2522,2523,2525,2526,2527,2528,2529,2530,2531,2532,2533,2536,2537,2538,2539,2541,2544,2545,2548,2553,2555,2558,2560,2561,2562,2563,2566,2567,2568,2569,2571,2572,2574,2575,2576,2577,2578,2580,2581,2582,2585,2588,2589,2590,2591,2592,2593,2598,2599,2600,2601,2602,2603,2605,2608,2610,2612,2613,2615,2616,2620,2621,2622,2623,2624,2625,2626,2628,2629,2631,2632,2633,2635,2638,2639,2642,2644,2645,2646,2650,2651,2652,2653,2655,2656,2659,2660,2663,2664,2665,2666,2667,2668,2670,2671,2673,2674,2675,2677,2678,2679,2680,2681,2683,2685,2686,2688,2689,2690,2691,2692,2693,2697,2698,2699,2700,2701,2702,2703,2705,2708,2710,2713,2714,2717,2719,2721,2722,2724,2725,2726,2727,2728,2729,2730,2731,2734,2736,2737,2739,2740,2741,2743,2744,2748,2751,2752,2754,2760,2762,2764,2765,2767,2769,2770,2771,2776,2779,2780,2781,2782,2783,2784,2785,2786,2787,2792,2794,2795,2796,2797,2801,2802,2803,2804,2807,2809,2810,2811,2813,2815,2819,2820,2824,2825,2827,2829,2830,2832,2833,2836,2838,2839,2840,2845,2847,2849,2853,2854,2856,2857,2858,2859,2860,2861,2863,2865,2866,2868,2871,2873,2874,2876,2878,2880,2881,2883,2889,2890,2895,2900,2904,2905,2906,2908,2910,2914,2915,2916,2917,2919,2920,2922,2923,2924,2928,2929,2931,2932,2938,2939,2940,2941,2944,2945,2947,2949,2950,2951,2952,2953,2954,2955,2956,2958,2964,2966,2967,2971,2972,2975,2980,2981,2984,2987,2990,2991,2993,2996,2998,2999,3000,3004,3005,3008,3011,3013,3016,3019,3020,3022,3023,3024,3025,3028,3031,3032,3033,3034,3035,3037,3038,3040,3042,3043,3044,3045,3047,3048,3049,3050,3051,3052,3056,3057,3060,3061,3062,3063,3064,3065,3067,3068,3069,3070,3071,3072,3073,3074,3076,3078,3079,3080,3082,3083,3086,3087,3088,3089,3090,3091,3092,3093,3094,3095,3096,3098,3099,3100,3102,3106,3107,3109,3111,3112,3114,3115,3116,3117,3118,3122,3123,3125,3126,3127,3129,3131,3132,3133,3134,3136,3137,3138,3139,3140,3142,3143,3144,3146,3147,3149,3153,3154,3156,3157,3158,3161,3164,3165,3168,3169,3174,3176,3178,3179,3180,3181,3182,3183,3185,3186,3187,3188,3190,3191,3192,3193,3196,3198,3200,3202,3205,3206,3207,3209,3211,3215,3217,3218,3220,3222,3223,3224,3225,3228,3230,3232,3234,3236,3237,3238,3239,3240,3241,3243,3245,3247,3249,3250,3254,3255,3257,3258,3261,3262,3263,3264,3266,3267,3270,3271,3272,3274,3276,3277,3278,3279,3281,3282,3284,3285,3288,3292,3293,3294,3296,3299,3300,3301,3302,3303,3304,3306,3307,3308,3310,3312,3316,3320,3322,3323,3324,3325,3326,3328,3329,3332,3334,3336,3337,3338,3339,3340,3342,3343,3345,3347,3354,3355,3357,3358,3359,3360,3361,3362,3363,3365,3366,3367,3369,3371,3372,3374,3376,3377,3378,3379,3380,3383,3385,3387,3393,3394,3396,3399,3400,3402,3403,3406,3408,3409,3410,3416,3417,3419,3425,3427,3428,3429,3432,3433,3435,3436,3438,3443]
	for cur_line in line_data:
		sent_id, inputline=cur_line.split(":")
		sent_id=int(sent_id)
		if sent_id in done_list:
			print("continuing")
			continue
			pass
		inputline=inputline.strip()
		cur_dataframe=getdatafromsite(inputline)
		conflict_dataframe=check_conflicts(inputline, cur_dataframe,sent_id)
		print (str(len(line_data)-line_data.index(cur_line))+" more to go.")
		pass
	pass

if __name__ == '__main__':
	cur_file=open('under_manual_sents.txt','r')
	line_data=cur_file.readlines()
	for cur_line in line_data:
		if "$$" not in cur_line:
			continue
			pass
		sent_id, inputurl=cur_line.split("$$")
		sent_id=int(sent_id)
		inputline=inputurl.strip()
		inputline=inputline.split("&text=")[1]
		inputline=inputline.split("&t=SL")[0]
		inputline=inputline.replace("+"," ")
		inputline=inputline.strip()
		# print (str(sent_id)+":"+inputline)
		cur_dataframe=getdatafromsite(inputline)
		conflict_dataframe=check_conflicts(inputline, cur_dataframe,sent_id)
		print (str(len(line_data)-line_data.index(cur_line))+" more to go.")
		pass
	pass
	
